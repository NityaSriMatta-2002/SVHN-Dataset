{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8266992,"sourceType":"datasetVersion","datasetId":4907759}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CNN ","metadata":{}},{"cell_type":"code","source":"!pip install torchsummary\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset, ConcatDataset, random_split\nfrom torchvision.models import vit_b_16\nfrom torchvision.transforms import ToPILImage, Resize, ToTensor, Normalize, Compose\nimport h5py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchsummary import summary\nfrom torch.utils.data import Dataset\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T14:10:58.838015Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_h5_dataset(filepath):\n    with h5py.File(filepath, 'r') as h5f:\n        flat_images = h5f['images'][:]\n        labels = h5f['labels'][:]\n        images = flat_images.reshape(-1, 64, 64, 3)\n        images = images.transpose((0, 3, 1, 2)) /255.0\n        images = torch.tensor(images, dtype=torch.float32)\n        labels = torch.tensor(labels.flatten(), dtype=torch.long)\n    return TensorDataset(images, labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding='same'),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.Conv2d(32, 32, kernel_size=3, padding='same'),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2,stride=2),\n            nn.Dropout(0.3),\n\n            nn.Conv2d(32, 64, kernel_size=3, padding='same'),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size=3, padding='same'),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2,stride=2),\n            nn.Dropout(0.3),\n\n            nn.Conv2d(64, 128, kernel_size=3, padding='same'),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, padding='same'),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2,stride=2),\n            nn.Dropout(0.3),\n\n            nn.Conv2d(128, 256, kernel_size=3, padding='same'),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, padding='same'),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2,stride=2),\n            nn.Dropout(0.3)\n        )\n        \n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64 * 8 * 8, 64), \n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(64, 10),\n            nn.Softmax(dim=1)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n\ndef l1_penalty(parameters, lambda_l1):\n    l1_norm = sum(p.abs().sum() for p in parameters if p.requires_grad)\n    return lambda_l1 * l1_norm\n\ndef train_model(model, num_epochs, train_loader, valid_loader, optimizer, criterion):\n    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss, correct, total = 0, 0, 0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n        history['train_loss'].append(train_loss / len(train_loader))\n        history['train_acc'].append(100 * correct / total)\n\n        # Validation phase\n        model.eval()\n        val_loss, correct, total = 0, 0, 0\n        with torch.no_grad():\n            for images, labels in valid_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                correct += (predicted == labels).sum().item()\n                total += labels.size(0)\n\n        history['val_loss'].append(val_loss / len(valid_loader))\n        history['val_acc'].append(100 * correct / total)\n\n        print(f'Epoch {epoch+1}: Train Loss: {train_loss / len(train_loader):.4f}, Train Acc: {100 * correct / total:.2f}%, Val Loss: {val_loss / len(valid_loader):.4f}, Val Acc: {100 * correct / total:.2f}%')\n\n    return history\n\n\n# Evaluation function\ndef evaluate_model(model,test_loader):\n    model.eval()\n    total_correct = 0\n    total_samples = 0\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total_samples += labels.size(0)\n            total_correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * total_correct / total_samples\n    print(f'Accuracy on test set: {accuracy:.2f}%')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_training_history(history):\n    epochs = range(1, len(history['train_loss']) + 1)\n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, history['train_loss'], 'bo-', label='Train Loss')\n    plt.plot(epochs, history['val_loss'], 'r+-', label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, history['train_acc'], 'bo-', label='Train Accuracy')\n    plt.plot(epochs, history['val_acc'], 'r+-', label='Validation Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load datasets\ntrain_dataset = load_h5_dataset('/kaggle/input/svhn-data/train.h5')\ntest_dataset = load_h5_dataset('/kaggle/input/svhn-data/test.h5')\n\ncombined_dataset = ConcatDataset([train_dataset, test_dataset])\n\n# Define split sizes\ntotal_size = len(combined_dataset)\ntrain_size = int(total_size * 0.65)\nvalid_size = int(total_size * 0.10)\ntest_size = total_size - train_size - valid_size\n\n# Randomly split the combined dataset\ntrain_dataset, valid_dataset, test_dataset = random_split(combined_dataset, [train_size, valid_size, test_size])\n\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True,num_workers=8)\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, drop_last=True,num_workers=8)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True,num_workers=8)\n\n# Model, optimizer, and loss function\nmodel = CNNModel().to(device)\noptimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.0001)\ncriterion = nn.CrossEntropyLoss()\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    model = torch.nn.DataParallel(model)\n\nhistory = train_model(model, 40, train_loader, valid_loader, optimizer, criterion)\nplot_training_history(history)\nevaluate_model(model,test_loader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"summary(model, (3,64,64))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model.pth')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_images(images, actual_labels, predicted_labels, num_images=6):\n    images = images.numpy()  # Convert images to numpy array\n    num_images = min(num_images, len(images))  # Ensure num_images does not exceed the number of available images\n\n    plt.figure(figsize=(15, 8))\n    for i in range(num_images):\n        image = np.transpose(images[i], (1, 2, 0))  # Transpose image dimensions for visualization\n        image = (image - np.min(image)) / (np.max(image) - np.min(image))  # Normalize image\n        plt.subplot(2, num_images, i + 1)\n        plt.imshow(image)  \n        plt.title(f\"Actual: {actual_labels[i]}\")\n        plt.axis('off')\n\n        plt.subplot(2, num_images, i + 1 + num_images)\n        plt.text(0.5, 0.5, f\"Predicted: {predicted_labels[i]}\", horizontalalignment='center', verticalalignment='center')\n        plt.axis('off')\n\n    plt.show()\n\n# Assume the model is loaded and configured, and the DataLoader is ready\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Debug the data loader to check if it's returning the correct data\nimages, actual_labels = next(iter(test_loader))\nprint(\"Images shape:\", images.shape)\nprint(\"Labels shape:\", actual_labels.shape)\n\n# Get predicted labels using the model\nimages = images.to(device)\nwith torch.no_grad():\n    outputs = model(images)\n    _, predicted_labels = torch.max(outputs, 1)\n\n# Move images and labels back to CPU for visualization\nimages = images.cpu()\nactual_labels = actual_labels.cpu()\npredicted_labels = predicted_labels.cpu()\n\n# Visualize predictions\nplot_images(images, actual_labels, predicted_labels, num_images=6)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Vision Transformer","metadata":{}},{"cell_type":"code","source":"class CustomH5Dataset(Dataset):\n    def __init__(self, file_path):\n        self.file_path = file_path\n        self.h5_file = h5py.File(self.file_path, 'r')\n        self.images = self.h5_file['images']\n        self.labels = self.h5_file['labels']\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        # Load image and label\n        image = self.images[idx].reshape(64, 3, 64)\n        image = torch.tensor(image, dtype=torch.float).permute(1, 2, 0)  # Change shape to HWC for PIL\n        label = int(self.labels[idx])\n        image = image / 255.0\n\n        # Transform image\n        transform = Compose([\n            ToPILImage(),\n            Resize((224, 224)),\n            ToTensor(),\n            Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n        image = transform(image)\n\n        return image, label\n\n    def close(self):\n        self.h5_file.close()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, num_epochs, train_loader, valid_loader, optimizer, criterion):\n    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss, correct, total = 0, 0, 0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n        history['train_loss'].append(train_loss / len(train_loader))\n        history['train_acc'].append(100 * correct / total)\n\n        # Validation phase\n        model.eval()\n        val_loss, correct, total = 0, 0, 0\n        with torch.no_grad():\n            for images, labels in valid_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                correct += (predicted == labels).sum().item()\n                total += labels.size(0)\n\n        history['val_loss'].append(val_loss / len(valid_loader))\n        history['val_acc'].append(100 * correct / total)\n\n        print(f'Epoch {epoch+1}: Train Loss: {train_loss / len(train_loader):.4f}, Train Acc: {100 * correct / total:.2f}%, Val Loss: {val_loss / len(valid_loader):.4f}, Val Acc: {100 * correct / total:.2f}%')\n\n    return history\n\n\n# Evaluation function\ndef evaluate_model(model,test_loader):\n    model.eval()\n    total_correct = 0\n    total_samples = 0\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total_samples += labels.size(0)\n            total_correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * total_correct / total_samples\n    print(f'Accuracy on test set: {accuracy:.2f}%')\n\ndef plot_training_history(history):\n    epochs = range(1, len(history['train_loss']) + 1)\n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, history['train_loss'], 'bo-', label='Train Loss')\n    plt.plot(epochs, history['val_loss'], 'r+-', label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, history['train_acc'], 'bo-', label='Train Accuracy')\n    plt.plot(epochs, history['val_acc'], 'r+-', label='Validation Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = CustomH5Dataset('/kaggle/input/svhn-data/train.h5')\ntest_dataset = CustomH5Dataset('/kaggle/input/svhn-data/test.h5')\n\n# Combine datasets\ncombined_dataset = ConcatDataset([train_dataset, test_dataset])\n\n# Split combined dataset into train, validation, and test sets\ntotal_size = len(combined_dataset)\ntrain_size = int(0.7 * total_size)\nvalid_size = int(0.15 * total_size)\ntest_size = total_size - train_size - valid_size\ntrain_dataset, valid_dataset, test_dataset = random_split(combined_dataset, [train_size, valid_size, test_size])\n\n# DataLoader setup\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=8)\nvalid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=True, num_workers=8)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=True, num_workers=8)\n\n# Model setup\nvit_model = vit_b_16(pretrained=True)\nvit_model.heads[0] = torch.nn.Linear(vit_model.heads[0].in_features, 10)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nvit_model.to(device)\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    vit_model = torch.nn.DataParallel(vit_model)\n\n# Optimizer and Loss Function\noptimizer = optim.Adam(vit_model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n# Train the model\nvit_history = train_model(vit_model, 20, train_loader, valid_loader, optimizer, criterion)\nplot_training_history(vit_history)\n\n# Evaluation\nevaluate_model(vit_model, test_loader)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_images(images, actual_labels, predicted_labels, num_images=6):\n    images = images.numpy()  # Convert images to numpy array\n    num_images = min(num_images, len(images))  # Ensure num_images does not exceed the number of available images\n\n    plt.figure(figsize=(15, 8))\n    for i in range(num_images):\n        image = np.transpose(images[i], (1, 2, 0))  # Transpose image dimensions for visualization\n        image = (image - np.min(image)) / (np.max(image) - np.min(image))  # Normalize image\n        plt.subplot(2, num_images, i + 1)\n        plt.imshow(image)  \n        plt.title(f\"Actual: {actual_labels[i]}\")\n        plt.axis('off')\n\n        plt.subplot(2, num_images, i + 1 + num_images)\n        plt.text(0.5, 0.5, f\"Predicted: {predicted_labels[i]}\", horizontalalignment='center', verticalalignment='center')\n        plt.axis('off')\n\n    plt.show()\n\n# Assume the model is loaded and configured, and the DataLoader is ready\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nvit_model.to(device)\n\n# Debug the data loader to check if it's returning the correct data\nimages, actual_labels = next(iter(test_loader))\nprint(\"Images shape:\", images.shape)\nprint(\"Labels shape:\", actual_labels.shape)\n\n# Get predicted labels using the model\nimages = images.to(device)\nwith torch.no_grad():\n    outputs = vit_model(images)\n    _, predicted_labels = torch.max(outputs, 1)\n\n# Move images and labels back to CPU for visualization\nimages = images.cpu()\nactual_labels = actual_labels.cpu()\npredicted_labels = predicted_labels.cpu()\n\n# Visualize predictions\nplot_images(images, actual_labels, predicted_labels, num_images=6)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(vit_model.state_dict(), 'vit_model.pth')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(vit_model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"summary(vit_model, (3,224,224))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}